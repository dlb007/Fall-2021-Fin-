{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Start by setting up your content import. You can use the same target content as you used for exercise two, or set up something new. \r\n",
    "# Read in and store the content from a single URL.\r\n",
    "\r\n",
    "import urllib.request, urllib.error, urllib.parse\r\n",
    "\r\n",
    "url = 'https://researchguides.dartmouth.edu/filmstudies/adaptations'\r\n",
    "\r\n",
    "response = urllib.request.urlopen(url)\r\n",
    "webContents = response.read()\r\n",
    "\r\n",
    "print(webContents[0:1000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'<!DOCTYPE html><html lang=\"en\"><head><meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" /><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /><title>Film adaptations - Film Studies - Research Guides at Dartmouth College</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"><meta name=\"robots\" content=\"noarchive\" /><!-- favicon.twig -->\\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/apple-touch-icon.png\">\\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/favicon-32x32.png\">\\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/favicon-16x16.png\">\\n<link rel=\"manifest\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/site.webmanifest\">\\n<link rel=\"mask-icon\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/safari-pinned-tab.svg\" color=\"#5bbad5\">\\n<link rel=\"shortcut icon\" href=\"//libapps.s3.amaz'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Next, splice the content you've imported to include only the primary text of interest. \r\n",
    "# You'll need to investigate the website you are looking at and choose strategically what tags you look for to define the starting and ending location of your splice. \r\n",
    "# Build on the model in CleaningHTML.ipynb\r\n",
    "\r\n",
    "contents = str(webContents)\r\n",
    "startLoc = contents.find(\"content=\\\"This guide\")\r\n",
    "endLoc = contents.find(\".\\\"/>\")\r\n",
    "\r\n",
    "print(startLoc)\r\n",
    "print(endLoc)\r\n",
    "\r\n",
    "contents = contents[startLoc: endLoc]\r\n",
    "print(contents[0: 500])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1589\n",
      "1760\n",
      "content=\"This guide is an introduction to the resources for Film Studies at Dartmouth.  If you are interested in Television, see the separate research guide for Television\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Implement a loop to remove all the HTML tags from your text. Use the model provided in CleaningHTML.ipynb, and make sure to store your cleaned text as a string. \r\n",
    "# Print the string and inspect the results. Save your now  cleaned text as a .txt file with an appropriate name.\r\n",
    "\r\n",
    "inside = 0\r\n",
    "text = ''\r\n",
    "\r\n",
    "for char in contents:\r\n",
    "    if char == '<':\r\n",
    "        inside = 1\r\n",
    "    elif (inside == 1 and char == '>'):\r\n",
    "        inside = 0\r\n",
    "    elif inside== 1:\r\n",
    "        continue\r\n",
    "    else: \r\n",
    "        text += char\r\n",
    "\r\n",
    "text = text.replace(\"\\\\n\",\"\")\r\n",
    "text = text.replace(\"\\\\r\",\"\")\r\n",
    "print(text[0: 500])\r\n",
    "\r\n",
    "f = open('chairreviews.txt','w')\r\n",
    "f.write(text)\r\n",
    "f.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "content=\"This guide is an introduction to the resources for Film Studies at Dartmouth.  If you are interested in Television, see the separate research guide for Television\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# As your bonus challenge for this week, identify at least one other area of content that needs cleaning from your file: \r\n",
    "# this might be URLs, {} content, special characters, or other \"noise\" you want to cut from your spring. \r\n",
    "# Using a combination of loops, conditionals, and string methods as appropriate, remove those elements from the text.\r\n",
    "\r\n",
    "inside = 0\r\n",
    "text = ''\r\n",
    "\r\n",
    "for char in contents:\r\n",
    "    if char == '<':\r\n",
    "        inside = 1\r\n",
    "    elif (inside == 1 and char == '>'):\r\n",
    "        inside = 0\r\n",
    "    elif inside== 1:\r\n",
    "        continue\r\n",
    "    else: \r\n",
    "        text += char\r\n",
    "\r\n",
    "print(text[0: 500])\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " content=\"This guide is an introduction to the resources for Film Studies at Dartmouth.  If you are interested in Television, see the separate research guide for Television\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Now we're ready to analyze our text. This time, try combining the elements we've used so far to handle our text by writing a simple algorithm following this model:\r\n",
    "\r\n",
    "# First, split your string into a \"bag of words\" by cutting at the whitespace into an array.\r\n",
    "\r\n",
    "text = text.lower()\r\n",
    "wordBag = text.split()\r\n",
    "\r\n",
    "\r\n",
    "# Next, create a loop that runs through every word in your new array\r\n",
    "# Within the loop, create some conditionals and behaviors to process the words. \r\n",
    "# For instance, you might print out every word that starts with a certain letter, or print out words longer than a set length, etc. \r\n",
    "# Try playing with the loop breaks and continue options to handle different types of words differently.\r\n",
    "\r\n",
    "for word in wordBag:\r\n",
    "    if word == \"pious\":\r\n",
    "        print(\"The reviewer has brought piety into this.\")\r\n",
    "    elif word == \"gender\" or word == \"race\":\r\n",
    "        print(\"The reviewer has acknowledged \" + word)\r\n",
    "    #note that gender doesn't work (in this dataset the punctuation interferes - we'll fix this next week!)\r\n",
    "    elif len(word) > 10:\r\n",
    "        print(word)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "content=\"this\n",
      "introduction\n",
      "television,\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "598d64e08a06bfba065a99698ec5bbec753236817de80e4f3bcf221574aa140c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}